{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede62786",
   "metadata": {},
   "source": [
    "Alexander S. Lundervold & Arvid Lundervold, 15.09.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ca703-dfb7-4c35-828e-1f69e1edae92",
   "metadata": {},
   "source": [
    "# Using deep learning to extract imaging-biomarkers for brain cancer analyses in MRI of glioma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66429334",
   "metadata": {},
   "source": [
    "<img width=40% src=\"https://upload.wikimedia.org/wikipedia/commons/6/64/Glioblastoma_macro.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476c104-c934-4924-a1b1-000f328f7545",
   "metadata": {},
   "source": [
    "In this notebook, we'll use a deep learning model to segment brain tumors from multi-parametric MRI and then extract features from the resulting tumor masks. Such features can potentially be associated with tumor severity and prognosis and contribute to better treatment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd837af",
   "metadata": {},
   "source": [
    "Extracting features from objects of interest in medical images for diagnostic purposes is often referred to as **radiomics**. The goal of radiomics is to extract information from medical images that can be used as part of a medical imaging-based diagnostic workflow. The information can be extracted from various imaging modalities, e.g., different MRI contrasts, PET imaging, CT imaging, and so on. One can then combine it with other sources of information (e.g., demographics, clinical data, genetics). In such a way, radiomics–and **radiogenomics**–can open the door to sophisticated and powerful analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb8bfe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Radiomics workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3685b3b-6c03-446e-9d46-17c4e308baf0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this notebook, we will estimate the locations and extent of the brain tumors' T2-enhancing and non-enhancing regions. We can then use this to extract the tumor location and the tumor burden. Additionally, we can look at the features of the MRI images inside each of these two tumor parts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05255c6-1cdf-4d2a-8f2c-61d40d060f7c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](assets/radiomics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486267c3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tumor segmentation provides tumor volumes and locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87255199",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tumor burden and anatomical locations are highly informative when assessing prognosis and planning treatment in brain tumors. Once we can segment the tumors, we automatically obtain tumor volumes. If we have repeated scans of the same tumors, we obtain estimates of tumor progression. By further analyses one can also estimate the anatomical locations of the tumors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146d548",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tumor segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e70850",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"assets/tumor_segmentation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd303340",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tumor progression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9723a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"assets/tumor_volumes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6230fc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tumor localization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14338784",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using software that can segment the brain into meaningful anatomical regions (for example, FreeSurfer), one can estimate the overlap between the tumor and these anatomical regions. This provides **tumor localization**, which is of course highly relevant for assessment and prognosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e39bb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9e/Brainanim.gif\">\n",
    "<center><small> Freesurfer parcellation and segmentation</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de6a57",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width=60% src=\"assets/tumor_locations.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a25c1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data from TCGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829bcb41-d986-4b08-9250-d4141d97cd30",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use data from the TCGA collection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981c2f2-d6f5-4f49-b46c-fe8437bf328c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](assets/tcga.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc25d8a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TMP\n",
    "\n",
    "DATA: https://www.dropbox.com/t/DkMHIn5XSzmxE0sM\n",
    "\n",
    "Extract to the folder `data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca833fc-50e7-4a4d-94e7-1d75b36c9ea9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be470a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As always, we need to import some libraries and decide where to fetch and store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b39937-3951-4938-a02d-b3fd5163229a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da608a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#%pip install hd_glio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45c7f9-935f-47d8-9fb5-040e06a1d428",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os, sys, pandas as pd, numpy as np, random, seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc15fa8-a31a-436d-a46b-5be45ca9592e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca050c2-f1f7-439c-b1dd-c08412d01abf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NB_DIR = Path.cwd()\n",
    "LOCAL_DATA = NB_DIR/'data'\n",
    "IMG_DATA = LOCAL_DATA/'TCGA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84734a-6375-4ed8-ac21-c6573bc47797",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Brain tumor imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497814d3-3fbb-497d-8bb8-0c98dbe515f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will use a small sample data set from the TCGA collection. For simplicity, we use versions of the MRI images that have already been co-registered and converted to NIfTI format: https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=24282668. This saves us a few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21fd39b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've prepared a small sample data set containing data from 10 subjects.\n",
    "\n",
    "> **Note:** The TCGA-GBM collection has data from 262 subjects. We use a small sample for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db876f4-7b97-49fb-82e0-f69f0294cfad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(LOCAL_DATA/'TCGA-sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe98d54-8f0c-429f-97c5-5bd1891bbc49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621f248-2799-44c3-8d9c-659fd08c4fa8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For convenience, the corresponding images have already been downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e1b15-e001-4116-bbf9-4601a7840c5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(list((IMG_DATA/sample_df['img_dir'].values[0]).iterdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077ec0f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here are all the subject IDs in our sample data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81ea60-a5a7-4f51-9cd7-b8e34957415c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subject_ids = sample_df['img_dir'].values\n",
    "subject_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09482d-88d1-4aec-be59-b2af19583b3f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "tags": []
   },
   "source": [
    "## Inspect some images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37e0d0-5747-459c-ae47-5b3f2a2ea97d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's very important to inspect your data. After fetching the data and after performing any transformations on the data. In the case of images, that typically means displaying the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113686c1-e5ae-4145-9f80-5f58163bba28",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_image(subj_id, slice_nb):\n",
    "    images = [nib.load(i) for i in sorted(list((IMG_DATA/subj_id).glob(\"*.nii*\")))]\n",
    "    nb_slices = images[0].shape[-1]\n",
    "    \n",
    "    flair, t1, t1c, t2 = [np.flip(np.rot90(i.get_fdata()[:,:,slice_nb])) for i in images]\n",
    "\n",
    "    f,axs = plt.subplots(1,4, figsize=(18,5))\n",
    "    axs[0].imshow(flair, cmap=\"gray\")\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(t1, cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].imshow(t1c, cmap=\"gray\")\n",
    "    axs[2].axis(\"off\")\n",
    "    axs[3].imshow(t2, cmap=\"gray\")\n",
    "    axs[3].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cb83b-11ba-4216-b466-6fbf03cff182",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_image(subject_ids[0], slice_nb=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c0240-5c07-4193-a953-6c03098382ae",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Understanding the data is such a crucial part of any machine learning project that it's worthwhile to spend a lot of time figuring out ways to construct functions to plot and to inspect features of the data. By using IPyWidgets, we can make our plots interactive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f594b6b-346e-4117-94b0-04c8b0a36776",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, IntSlider, Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c987c-a55e-40af-963e-b5cd1eb905bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select_layer = IntSlider(value=100, min=0, max=154, \n",
    "                         description='Slice', continuous_update=False)\n",
    "\n",
    "select_subj = Select(options=subject_ids, description=\"Subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada05f23-5f23-4c34-9c0a-8a5e61a0b2b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interactive(plot_image, subj_id=select_subj, slice_nb=select_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0268f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We should also attempt to understand the _distribution_ of the downloaded data in various ways. We can for example ask what  the variation in mean voxel intensities is for each of the image sequences (whole-brain intensities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f5a27",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "intensities = {}\n",
    "for subj_id in subject_ids:\n",
    "    flair, t1, t1c, t2 = [np.mean(nib.load(i).get_fdata()) for i in sorted(list((IMG_DATA/subj_id).glob(\"*.nii*\")))]\n",
    "    intensities[subj_id] = [flair, t1, t1c, t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efca7db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_intensities = pd.DataFrame.from_dict(intensities, orient='index', \n",
    "                                       columns = ['flair', 't1', 't1c', 't2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4748823",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad98e13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_intensities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb8004",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We observe quite some variation in the mean voxel intensities across the data set. This leads to a need for some kind of normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612325b3-6eb6-4701-bf35-09db2c29df8a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Brain tumor segmentation using HD-GLIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb9937-469b-4c70-a651-548a73c76b61",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this case, we will use an existing model that has already been trained on a large collection of MRI examinations (3220 examinations from 1450 brain tumor patients, sourced from multiple centers). The pipeline, including the trained model and various preprocessing steps, is freely available via the code-sharing platform **GitHub** under an **open source license** (Apache-2.0): https://github.com/NeuroAI-HD/HD-GLIO. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfbe76-bb9c-4ab8-bdb9-1c88fd0924cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](assets/open-source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68527af-5ae7-46dd-b664-fe96fcb876d1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "HD-GLIO was constructed as a collaboration between the Department of Neuroradiology at the Heidelberg University Hospital, Germany and the Division of Medical Image Computing at the German Cancer Research Center (DKFZ) Heidelberg, Germany."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f5de7-e5b0-4967-a2a5-404201e5d129",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The network architecture: U-Net and the nnU-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793dc941-e7ca-4fd1-93df-fb19c221b0aa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "HD-GLIO is based on a version of the widely used U-Net architecture (also used in our previous notebook). Specifically, it is based on a variant of the open source nnU-Net (\"no-new-Net\"), available here: https://github.com/MIC-DKFZ/nnUNet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d92ae7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**U-Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bdeb6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](https://miro.medium.com/max/1400/1*x0kR2rGlTibVbu8InCNBVg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a9096",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**nnUNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350733d0-1f2b-4e0b-897d-e8dedfe3d404",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The main point of nnUNet is that there is a lot of performance gains to be had by optimizing the deep learning workflow--preprocessing, postprocessing, etc, rather than creating completely new artificial neural network architectures. You can read all about the ideas here: https://www.nature.com/articles/s41592-020-01008-z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a1e88-ddda-4db6-a63b-6a31fb37272d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig2_HTML.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f134fe-fa41-4a8c-868f-b79ec47e2062",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Running HD-GLIO on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97a349-264c-4812-adb2-ff524cf40551",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We create a small helper function to run HD-GLIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663809e-13e3-4c38-b08b-74be89d09456",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_hdglio(t1, t1c, t2, flair, output, verbose=True):\n",
    "    \n",
    "    if verbose: \n",
    "        !CUDA_VISIBLE_DEVICES=0 $sys.exec_prefix/bin/hd_glio_predict -t1 $t1 -t1c $t1c -t2 $t2 -flair $flair -o $output\n",
    "    if not verbose:\n",
    "        !CUDA_VISIBLE_DEVICES=0 $sys.exec_prefix/bin/hd_glio_predict -t1 $t1 -t1c $t1c -t2 $t2 -flair $flair -o $output > /dev/null\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150863e8-05e2-43ec-aad1-6b07dfda7c80",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...and run the already trained model on all our subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4717dfc-1670-4856-997a-f34d35bfae0e",
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "verbose=True\n",
    "\n",
    "i=1\n",
    "for subj in subject_ids:\n",
    "    \n",
    "    # Specify the file name for the output segmentation\n",
    "    output_file = LOCAL_DATA/\"TCGA\"/subj/\"seg\"/f\"{subj.split('/')[-1]}_seg.nii.gz\"\n",
    "    \n",
    "    # Grab the file names for the four images (T1, T1c, T2, FLAIR)\n",
    "    flair, t1, t1c, t2 = sorted(list((IMG_DATA/subj).glob(\"*.nii*\")))\n",
    "    \n",
    "    # Run HDGLIO (note that it is possible to run HD-GLIO in batch mode, avoiding \n",
    "    # having to load the model every time. See the HD-GLIO docs for more)\n",
    "    print(f\"Processing subject #{i}/{len(subject_ids)}: {subj.split('/')[-1]}\")\n",
    "    \n",
    "    run_hdglio(t1, t1c, t2, flair, output_file, verbose)\n",
    "    \n",
    "    print(\"-\"*40)\n",
    "    print(f\"DONE. Output available at {output_file}\")\n",
    "    print()\n",
    "    print(\"#\"*40)\n",
    "    print(\"#\"*40)\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43ff7c-4389-4580-814b-f13b547a9b5c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ba1c5-d750-4c84-b3c4-f97946b5e751",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've now produced segmentation masks for our tumor images. Here's a a small widget to plot the resulting segmentation masks and the corresponding T2 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc1f60-0a09-4be8-a657-ed2704209e99",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import ToggleButtons, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90152b-9c73-4516-be48-ee919a31d0ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes_dict = {\n",
    "    'Normal': 0.,\n",
    "    'Contrast-enhancing': 1.,\n",
    "    'Non-enhancing': 2.,\n",
    "}\n",
    "\n",
    "channel_dict = {\n",
    "    'Flair': 0.,\n",
    "    'T1': 1.,\n",
    "    'T1c': 2.,\n",
    "    'T2': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f1dd6-0a9d-4fc8-93e5-ff279fa1293e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "def plot_segmentation(subj_id, channel, seg_class, slice_nb):\n",
    "    \n",
    "    flair, t1, t1c, t2 = [nib.load(i) for i in sorted(list((IMG_DATA/subj_id).glob(\"*.nii*\")))]\n",
    "    mri_channels = {'Flair': flair, 'T1': t1, 'T1c': t1c, 'T2': t2}\n",
    "    \n",
    "    mask = nib.load(list((IMG_DATA/subj_id/\"seg\").glob(\"*.nii*\"))[0])\n",
    "    \n",
    "    nb_slices = mri_channels[channel].shape[-1]\n",
    "    \n",
    "    img_data = np.flip(np.rot90(mri_channels[channel].get_fdata()[:,:,slice_nb]))\n",
    "    mask_data = np.flip(np.rot90(mask.get_fdata()[:,:,slice_nb]))\n",
    "    \n",
    "    print(f\"Label: {seg_class}\")\n",
    "    img_label = classes_dict[seg_class]\n",
    "    mask = np.where(mask_data == img_label, 255, 0)\n",
    "    \n",
    "    f,axs = plt.subplots(1,3, figsize=(18,5))\n",
    "    axs[0].imshow(img_data, cmap=\"gray\")\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(mask, cmap='binary')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].imshow(mask, cmap=\"Blues\")\n",
    "    axs[2].imshow(img_data, cmap=\"gray\", alpha=0.7)\n",
    "    axs[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d1307-ab71-422b-a5d8-afe005310de4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set up the interactive elements of our widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4ef56-1644-48a8-95c4-6ab10d526acf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Button\n",
    "select_class = ToggleButtons(\n",
    "    options=['Contrast-enhancing', 'Non-enhancing'],\n",
    "    description='Select Label:',\n",
    "    button_style='info', \n",
    "    \n",
    ")\n",
    "select_channel = ToggleButtons(\n",
    "    options=list(channel_dict.keys()),\n",
    "    description='Select Channel:',\n",
    "    button_style='info', \n",
    "    \n",
    ")\n",
    "\n",
    "# Slice slider\n",
    "select_layer = IntSlider(value=100, min=0, max=254, \n",
    "                         description='Slice', continuous_update=False)\n",
    "\n",
    "# Subject selector\n",
    "select_subj = Select(options=subject_ids, description=\"Subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286ee37-547a-484b-a190-d69efb26cf81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interactive(plot_segmentation, channel=select_channel, subj_id=select_subj,\n",
    "            seg_class=select_class, slice_nb=select_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a0e1d-5416-4970-9e2d-263bc66e82c3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Radiomics: extracting tumor features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d9a4b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](assets/radiomics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19b813",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Volume and location information for tumors is important, but there's a lot more information represented in the images. Information that could be useful for more precise diagnosis and prognosis. For example, the shape of the tumors, the tumors appearance in the different MRI contrast images, the heterogeneity in the various compartments of the tumors, and so on. As mentioned, such ideas leads us to **radiomics**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ec5a3-ef4c-4765-89e6-4f046732a021",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a vast number of possible features to extract (at least several hundreds, depending on the number of imaging modalities), related to shape, intensity values and variation, and texture features from each of the MRI modalities. The robustness and relevance of the various features is somewhat unclear, but there's a lot of research into the clinical relevance of radiomics.\n",
    "\n",
    "For demonstration purposes, we extract only the total volumes, a few shape features, and some texture information. More precisely, we extract:\n",
    "\n",
    "1. The size of the enhancing and non-enhancing tumor\n",
    "2. The maximum 3D diameter\n",
    "3. Mean and variance of the intensities in the T1, T1c, T2, FLAIR in the enhancing and non-enhancing areas\n",
    "4. The gray level nonuniformity in T1, T1c, T2, FLAIR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8761c00",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data-driven science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b6f50",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Note:** It is interesting to contrast _data-driven_ and biologically and clinically inspired analyses. In principle, one can use and discover complicated features that are linked to important outcomes (e.g., survival) _driectly from the data_. Features that are potentially not understood from a biological point of view. This can, of course, also be quite dangerous, as one may uncover _spurious, meaningless patterns_ in the data one has collected. There will also be issues with _explainability_ if one drops the link to biological explanations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b453d81",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### RANO criteria for Glioblastoma Multiforme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a9cf7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"assets/rano.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4d481",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Extracting features using PyRadiomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ab5f9-7f71-4fe8-a8f4-4b9bbc0d4a7f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To extract radiomic features, we use an established, open-source library developed by the imaging community, PyRadiomics. The library aims to be the reference standard for radiomic analysis, easing both analyses and enabling greater reproducibility. PyRadiomics is available on GitHub: https://github.com/AIM-Harvard/pyradiomics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f5cde",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://www.radiomics.io/img/pyrad1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0190b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"assets/pyradiomics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde5ac2-95d0-4444-a7c4-19efb08f5a85",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We specify the features we'd like to extract in a file (YAML format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a4ea6-cb10-4e6c-9be3-38fdd2b15fce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#%cat pyradiomics_settings.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d61bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from radiomics import featureextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e970ec-fcd0-457a-b4dc-4c58c965d333",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_radiomics(images, mask, params='pyradiomics_settings.yaml'):\n",
    "    results = {}\n",
    "    \n",
    "    subject_id = images[0].stem.split(\"_\")[0]\n",
    "    results['SUBJECT ID'] = subject_id\n",
    "    \n",
    "    # Some features are the same across all individual MRI image sequences \n",
    "    # We can extract them from any sequence\n",
    "\n",
    "    extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "    extractor.loadParams(params)\n",
    "    \n",
    "    \n",
    "    result_label1 = extractor.execute(str(images[0]), mask, label=1)\n",
    "    result_label2 = extractor.execute(str(images[0]), mask, label=2)\n",
    "        \n",
    "    results[f'Volume_label1'] = result_label1['original_shape_MeshVolume'].round(2)\n",
    "    results[f'Volume_label2'] = result_label2['original_shape_MeshVolume'].round(2)\n",
    "        \n",
    "    results[f'Max3DDiameter_label1'] = result_label1['original_shape_Maximum3DDiameter'].round(2)\n",
    "    results[f'Max3DDiameter_label2'] = result_label2['original_shape_Maximum3DDiameter'].round(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Other features we extract from each individual type of MRI image\n",
    "\n",
    "    for img in images:\n",
    "        img_type = img.stem.split(\"_\")[-1].split(\".\")[0]\n",
    "        result_label1 = extractor.execute(str(img), mask, label=1)\n",
    "        result_label2 = extractor.execute(str(img), mask, label=2)\n",
    "        \n",
    "        \n",
    "        # Mean intensity\n",
    "        \n",
    "        results[f'{img_type}_MeanIntensity_label1'] = result_label1['original_firstorder_Mean'].round(2)\n",
    "        results[f'{img_type}_MeanIntensity_label2'] = result_label2['original_firstorder_Mean'].round(2)\n",
    "        \n",
    "        # Intensity variance\n",
    "        \n",
    "        results[f'{img_type}_IntensityVariance_label1'] = result_label1['original_firstorder_Variance'].round(2)\n",
    "        results[f'{img_type}_IntensityVariance_label2'] = result_label2['original_firstorder_Variance'].round(2)\n",
    "        \n",
    "        # Gray level nonuniformity\n",
    "        \n",
    "        results[f'{img_type}_GrayLevelNonUniformity_label1'] = result_label1['original_gldm_GrayLevelNonUniformity'].round(2)\n",
    "        results[f'{img_type}_GrayLevelNonUniformity_label2'] = result_label2['original_gldm_GrayLevelNonUniformity'].round(2)       \n",
    "        \n",
    "        \n",
    "    results = pd.DataFrame.from_dict(results, orient='index').T\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa45a8-812e-4d8b-bd5f-c1de1853b9ae",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Run extraction on all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082f843",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "i=1\n",
    "for subject_id in subject_ids:\n",
    "    print(f\"#{i}: Computing radiomic features for subject {subject_id}\")\n",
    "    images = sorted(list((LOCAL_DATA/'TCGA'/subject_id).glob('*.nii.gz')))\n",
    "    mask = str(list((LOCAL_DATA/'TCGA'/subject_id/'seg').glob('*.nii.gz'))[0])\n",
    "    res = get_radiomics(images, mask)\n",
    "    results.append(res)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930bd65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We construct a data frame that stores the resulting radiomic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1091c8a-7ffd-4285-b3c8-69939488a3b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "radiomic_df = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3456428-3a3f-46e3-8b1e-884c0826ad32",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "radiomic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c4a47",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "radiomic_df['tumor_volume'] = radiomic_df['Volume_label1'] + radiomic_df['Volume_label2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1dc5c-de98-4fe8-9126-d681a4e56d0e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Construct our final data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea8b64-db6f-4fc0-b715-72bddef6cd4c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can append these features to the other information we have about each subject in the data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06678027-a95d-4cc8-b090-5d353931286d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ab7d6-6480-465d-89cd-6ecbb7d2c5d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(sample_df, radiomic_df, on=\"SUBJECT ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83200085",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're left with quite an interesting data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1f86a-f3a8-4ddf-8149-bb9956ff9eaa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595b2b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(LOCAL_DATA/'tcga_radiomics_sample.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72bbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(LOCAL_DATA/'tcga_radiomics_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c24dbb-7b1e-4572-9059-601a4bccb233",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b42d4-039c-4d75-b596-d577693ad80e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It would be natural to investigate whether the radiomic features together with the other information we have about the subjects can provide relevant clinical information. In other words, to what extent the various features are associated to clinical outcomes (e.g., survival), either individually or together. This can be done using e.g., plots, basic statistics, statistical modelling, or machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2e11e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's a plot of the length of survival for our subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08fb572",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd4b37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.scatterplot(x='SUBJECT ID', y='Survival(months)', hue='SUBJECT ID',\n",
    "                     data=df.sort_values(by='Survival(months)'), s=60)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb70ce",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the total tumor volume versus length of survival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ba076",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.scatterplot(x='tumor_volume', y='Survival(months)', hue='SUBJECT ID',\n",
    "                     data=df.sort_values(by='Survival(months)'), s=60)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6df8d-c198-4b6a-b2db-6339ae64e036",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can bin the survival data into two: <= 5 months, > 5 months, and then study how this relates to the various radiomics features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43629a-98db-4d11-b2e6-214db6e8254c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['short_survival'] = (df['Survival(months)'] <= 5).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a03c7-71a0-40f8-8772-09ef11329012",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15cba6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's a plot investigating the relation between the IDH status, survival times and volume of the enhancing-non-enhancing tumor regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b7c90-aa74-48d4-a05e-2422647e3d76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.stripplot(data=df, x=\"short_survival\", y=\"Volume_label1\", hue='IDH-status',palette=\"vlag\", s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651e4c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Integrated diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae62f0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that multiple sources of information beyond MRI could be valuable when assessing a glioblastoma case. A system tasked with extracting relevant, actionable information should therefore have access to more than the MRI images. \n",
    "\n",
    "This is a general principle in medicine: important information about a patient, disease, or condition is represented in a vast set of heterogeneous data. This leads to the need for **integrated diagnostics**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be0ac4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width=40% src=\"assets/fusion.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2e738",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"assets/integrated_diagnostics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719d99d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# What's next in the workshop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304e559",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our sample data set is very small so we cannot say much at this point, but if you rerun this experiment using all the data available in TCGA-GBM you will have a data set that is quite large, comparably speaking. All the data is available through the TCGA database (after a simple access application process). You're therefore very close to being able to do some exciting research into brain tumors! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc377998",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Image segmentation: the holy grail of medical image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a1314",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As you observed, a crucial component in the above story was the need for accurate image segmentation techniques. This gave us our _regions-of-interest_, without which we would've been unable to perform our analysis. This is a general principle in medical image analysis, and image segmentation is often called **the holy grail of medical image analysis**. \n",
    "\n",
    "We saw that **deep learning** gave us an approach to image segmentation. That is one reason–among many–we should take a closer look at deep learning. We turn to this next. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3013f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a21f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you're interested in expanding the above radiomics analysis, I'm happy to discuss some possible starting points. One would f.ex. expand the data set and use a different segmentation model. And then conduct a careful statistical study of the various possible radiomic features (and also think about their their relevance).\n",
    "\n",
    "Here are some pointers:\n",
    "\n",
    "## Data\n",
    "<a href=\"https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=24282668\"><img src=\"assets/tcia-segm.png\"></a>\n",
    "<br><br>\n",
    "<a href=\"https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=1966258\"><img src=\"assets/tcga-gbm.png\"></a>\n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "<a href=\"https://github.com/rixez/brats21_kaist_mri_lab\"><img src=\"assets/nnunet-seg-model.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7b0d7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017640c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a href=\"https://github.com/mmiv-center/Research-Information-System/tree/master/components/Workflow-Image-AI\"><img src=\"assets/deploy.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a1a63",
   "metadata": {
    "hidden": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdglio",
   "language": "python",
   "name": "hdglio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
